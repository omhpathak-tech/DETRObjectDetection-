# -*- coding: utf-8 -*-
"""DETRObjectDetection.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TGLc3Y9di4ZWxUxBW0vzlzmwS2v7evG2
"""

!git clone https://github.com/facebookresearch/detr.git
import os
os.chdir('detr')
!git checkout a54b77800eb8e64e3ad0d8237789fcbf2f8350c5

import argparse 
import random 
from pathlib import Path 
import numpy as np 
import torch 
import torchvision.transforms as T 
import matplotlib.pyplot as plt 
import PIL.Image 

import util.misc as utils 
from models import build_model 

from main import get_args_parser

parser = argparse.ArgumentParser(description='DETR args parser', parents=[get_args_parser()])
args = parser.parse_args(args=[])
args.resume = 'https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth'
args.device = 'cpu'

if args.output_dir:
    Path(args.output_dir).mkdir(parents=True, exist_ok=True)

args.distributed = False 
print(args)

model, criterion, postprocessors = build_model(args)

device = torch.device(args.device)
model.to(device)

output_dir = Path(args.output_dir)
if args.resume:
  # the model will download the weights and model state from the https link provided 
  if args.resume.startswith('https'):
    checkpoint = torch.hub.load_state_dict_from_url(
        args.resume, map_location = 'cpu', check_hash = True
    ) 
  else:
    checkpoint = torch.load(args.resume, map_location='cpu')
  
  # this load the weights and model state into the model 
  model.load_state_dict(checkpoint['model'], strict = True)

# COCO classes
CLASSES = [
   'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',
   'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',
   'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',
   'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',
   'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',
   'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
   'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',
   'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',
   'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',
   'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',
   'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',
   'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',
   'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
   'toothbrush'
]

# colors for visualization
COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],
          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]

# standard PyTorch mean-std input image normalization
transform = T.Compose([
    T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# for output bounding box post-processing
def box_cxcywh_to_xyxy(x):
    x_c, y_c, w, h = x.unbind(1)
    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),
         (x_c + 0.5 * w), (y_c + 0.5 * h)]
    return torch.stack(b, dim=1)

def rescale_bboxes(out_bbox, size):
    img_w, img_h = size
    b = box_cxcywh_to_xyxy(out_bbox)
    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)
    return b

def detect(im, model, transform):
  # mean-std normalize the input image (batch-size: 1)
  img = transform(im).unsqueeze(0)

  # demo the model only support by default images with aspect ration betweeen 0.5 and 2
  # if you want to use images with an aspect ration outside this range 
  # rescale your image so that the maximum size at most 1333 for best results 
  assert img.shape[-2] <= 1600 and img.shape[-1] <= 1600, 'demo model only supports images up to 1600 pixels on each side'
 
  # propagate through the model 
  outputs = model(img)

  # keep only predictions with 0.7+ confidence 
  probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]
  keep = probas.max(-1).values > 0.7

  # convert boxes from [0; 1] to image scales 
  bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)
  return probas[keep], bboxes_scaled

def plot_results(pil_img, prob, boxes, classes):
  plt.figure(figsize=(16, 10))
  plt.imshow(pil_img)
  ax = plt.gca()
  for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), COLORS * 100):
    cl = p.argmax()
    if CLASSES[cl] not in classes: # only plot these classes 
      continue 
    ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=c, linewidth=3))

    text = f'{CLASSES[cl]}: {p[cl]:0.2f}'
    ax.text(xmin, ymin, text, fontsize=15, bbox=dict(facecolor='yellow', alpha=0.5))
  plt.axis('off')
  plt.show()

the_image = PIL.Image.open('/content/000000513524.jpg')
scores, boxes = detect(the_image, model, transform)

plot_classes = ['person']

plot_results(the_image, scores, boxes, plot_classes)

!gdown --id 1nKot1S6ARpB6wnyx3R1tefduUiUIjO9p
!gdown --id 1rkUK6OG7js5gYt1bhCUanPNqmuxwkVZX

!unzip -q WIDER_train.zip -d ./data
!unzip -q WIDER_val.zip -d ./data

!wget http://mmlab.ie.cuhk.edu.hk/projects/WIDERFace/support/bbx_annotation/wider_face_split.zip

!unzip -q wider_face_split.zip -d ./data

import os
import cv2
import sys
import json
import numpy as np
import shutil
from tqdm.notebook import tqdm


def widerface2coco(outputpath, image_root,json_name, annopath):
  dataset = { "info": {
              "description": "WIDER face in COCO format.",
              "url": "",
              "version": "1.1",
              "contributor": "aimhabo",
              "date_created": "2020-09-29"},
              "images": [],
              "annotations": [],
              "categories": [{"supercategory": "person", "id": 1, "name": "person"}, 
                             {"supercategory": "vehicle", "id": 2, "name": "bicycle"}, 
                             {"supercategory": "vehicle", "id": 3, "name": "car"}, 
                             {"supercategory": "vehicle", "id": 4, "name": "motorcycle"}, 
                             {"supercategory": "vehicle", "id": 5, "name": "airplane"}, 
                             {"supercategory": "vehicle", "id": 6, "name": "bus"}, 
                             {"supercategory": "vehicle", "id": 7, "name": "train"}, 
                             {"supercategory": "vehicle", "id": 8, "name": "truck"}, 
                             {"supercategory": "vehicle", "id": 9, "name": "boat"}, 
                             {"supercategory": "outdoor", "id": 10, "name": "traffic light"}, 
                             {"supercategory": "outdoor", "id": 11, "name": "fire hydrant"}, 
                             {"supercategory": "outdoor", "id": 13, "name": "stop sign"}, 
                             {"supercategory": "outdoor", "id": 14, "name": "parking meter"}, 
                             {"supercategory": "outdoor", "id": 15, "name": "bench"}, 
                             {"supercategory": "animal", "id": 16, "name": "bird"}, 
                             {"supercategory": "animal", "id": 17, "name": "cat"}, 
                             {"supercategory": "animal", "id": 18, "name": "dog"}, 
                             {"supercategory": "animal", "id": 19, "name": "horse"}, 
                             {"supercategory": "animal", "id": 20, "name": "sheep"}, 
                             {"supercategory": "animal", "id": 21, "name": "cow"}, 
                             {"supercategory": "animal", "id": 22, "name": "elephant"}, 
                             {"supercategory": "animal", "id": 23, "name": "bear"}, 
                             {"supercategory": "animal", "id": 24, "name": "zebra"}, 
                             {"supercategory": "animal", "id": 25, "name": "giraffe"}, 
                             {"supercategory": "accessory", "id": 27, "name": "backpack"}, 
                             {"supercategory": "accessory", "id": 28, "name": "umbrella"}, 
                             {"supercategory": "accessory", "id": 31, "name": "handbag"}, 
                             {"supercategory": "accessory", "id": 32, "name": "tie"}, 
                             {"supercategory": "accessory", "id": 33, "name": "suitcase"}, 
                             {"supercategory": "sports", "id": 34, "name": "frisbee"}, 
                             {"supercategory": "sports", "id": 35, "name": "skis"}, 
                             {"supercategory": "sports", "id": 36, "name": "snowboard"}, 
                             {"supercategory": "sports", "id": 37, "name": "sports ball"}, 
                             {"supercategory": "sports", "id": 38, "name": "kite"}, 
                             {"supercategory": "sports", "id": 39, "name": "baseball bat"}, 
                             {"supercategory": "sports", "id": 40, "name": "baseball glove"}, 
                             {"supercategory": "sports", "id": 41, "name": "skateboard"}, 
                             {"supercategory": "sports", "id": 42, "name": "surfboard"}, 
                             {"supercategory": "sports", "id": 43, "name": "tennis racket"}, 
                             {"supercategory": "kitchen", "id": 44, "name": "bottle"}, 
                             {"supercategory": "kitchen", "id": 46, "name": "wine glass"}, 
                             {"supercategory": "kitchen", "id": 47, "name": "cup"}, 
                             {"supercategory": "kitchen", "id": 48, "name": "fork"}, 
                             {"supercategory": "kitchen", "id": 49, "name": "knife"}, 
                             {"supercategory": "kitchen", "id": 50, "name": "spoon"}, 
                             {"supercategory": "kitchen", "id": 51, "name": "bowl"}, 
                             {"supercategory": "food", "id": 52, "name": "banana"}, 
                             {"supercategory": "food", "id": 53, "name": "apple"}, 
                             {"supercategory": "food", "id": 54, "name": "sandwich"}, 
                             {"supercategory": "food", "id": 55, "name": "orange"}, 
                             {"supercategory": "food", "id": 56, "name": "broccoli"}, 
                             {"supercategory": "food", "id": 57, "name": "carrot"}, 
                             {"supercategory": "food", "id": 58, "name": "hot dog"}, 
                             {"supercategory": "food", "id": 59, "name": "pizza"}, 
                             {"supercategory": "food", "id": 60, "name": "donut"}, 
                             {"supercategory": "food", "id": 61, "name": "cake"}, 
                             {"supercategory": "furniture", "id": 62, "name": "chair"}, 
                             {"supercategory": "furniture", "id": 63, "name": "couch"}, 
                             {"supercategory": "furniture", "id": 64, "name": "potted plant"}, 
                             {"supercategory": "furniture", "id": 65, "name": "bed"}, 
                             {"supercategory": "furniture", "id": 67, "name": "dining table"}, 
                             {"supercategory": "furniture", "id": 70, "name": "toilet"}, 
                             {"supercategory": "electronic", "id": 72, "name": "tv"}, 
                             {"supercategory": "electronic", "id": 73, "name": "laptop"}, 
                             {"supercategory": "electronic", "id": 74, "name": "mouse"}, 
                             {"supercategory": "electronic", "id": 75, "name": "remote"}, 
                             {"supercategory": "electronic", "id": 76, "name": "keyboard"}, 
                             {"supercategory": "electronic", "id": 77, "name": "cell phone"}, 
                             {"supercategory": "appliance", "id": 78, "name": "microwave"}, 
                             {"supercategory": "appliance", "id": 79, "name": "oven"}, 
                             {"supercategory": "appliance", "id": 80, "name": "toaster"}, 
                             {"supercategory": "appliance", "id": 81, "name": "sink"}, 
                             {"supercategory": "appliance", "id": 82, "name": "refrigerator"}, 
                             {"supercategory": "indoor", "id": 84, "name": "book"}, 
                             {"supercategory": "indoor", "id": 85, "name": "clock"}, 
                             {"supercategory": "indoor", "id": 86, "name": "vase"}, 
                             {"supercategory": "indoor", "id": 87, "name": "scissors"}, 
                             {"supercategory": "indoor", "id": 88, "name": "teddy bear"}, 
                             {"supercategory": "indoor", "id": 89, "name": "hair drier"}, 
                             {"supercategory": "indoor", "id": 90, "name": "toothbrush"}],
  }

  phase = json_name

  with open(annopath,'r') as f:
      lines = f.readlines()
      num_lines = len(lines)
      i_l=0
      img_id=1
      anno_id=1
      imagepath=None

      pbar = tqdm(total=num_lines)

      while i_l < num_lines:
          if len(lines[i_l]) < 1:
              break
          if '--' in lines[i_l]:
              imagepath=lines[i_l].strip()
              im=image_root+imagepath
              if (not os.path.exists(im)):
                print(im)
                break
              im = cv2.imread(im)
              height, width, channels = im.shape
              dataset["images"].append({"file_name": imagepath, "coco_url": "local", "height": height, "width": width, "flickr_url": "local", "id": img_id})
              i_l+=1
              pbar.update(1)
              num_gt=int(lines[i_l])
              while num_gt>0:
                  i_l+=1
                  pbar.update(1)
                  x1,y1,wid,hei=list(map(int, lines[i_l].split()))[:4]
                  num_gt-=1
                  dataset["annotations"].append({
                      "segmentation": [],
                      "iscrowd": 0,
                      "area": wid * hei,
                      "image_id": img_id,
                      "bbox": [x1, y1, wid, hei],
                      "category_id": 1,
                      "id": anno_id})
                  anno_id = anno_id + 1
                  #if im is not None:
                  #    cv2.rectangle(im,(x1,y1),(x1+wid,y1+hei), (0,0,0), 3)
                  #    cv2.rectangle(im,(x1,y1),(x1+wid,y1+hei), (255,255,255), 1)
              img_id+=1
              #if im is not None:
              #    cv2.imshow('img', im)
              #    cv2.waitKey(0)
          i_l+=1
          pbar.update(1)
          
      pbar.close()

  json_name = os.path.join(outputpath, "{}.json".format(phase))

  with open(json_name, 'w') as f:
      json.dump(dataset, f)

outputpath = "./data/"
# Validation set 
image_root_val = './data/WIDER_val/images/'
json_name_val = "WIDERFaceValCOCO"
annopath_val = './data/wider_face_split/wider_face_val_bbx_gt.txt'
# Training set 
image_root_train = './data/WIDER_train/images/'
json_name_train = "WIDERFaceTrainCOCO"
annopath_train = './data/wider_face_split/wider_face_train_bbx_gt.txt'

widerface2coco(outputpath, image_root_train, json_name_train, annopath_train)
widerface2coco(outputpath, image_root_val, json_name_val, annopath_val)

with open('./data/WIDERFaceTrainCOCO.json', 'r') as fp:
  train_json = json.load(fp)

print(len(train_json['images']))
print(len(train_json['annotations']))

with open('./data/WIDERFaceValCOCO.json', 'r') as fv:
  val_json = json.load(fv)

print(len(val_json['images']))
print(len(val_json['annotations']))

os.chdir('/content/detr')

!python main.py --coco_path './data' --epochs 2 --batch_size 3 --resume 'https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth' --output_dir './ckpts'

parser = argparse.ArgumentParser(description='DETR args parser', parents=[get_args_parser()])
args = parser.parse_args(args=[])
args.resume = 'ckpts/checkpoint.pth'
args.device = 'cpu'

if args.output_dir:
    Path(args.output_dir).mkdir(parents=True, exist_ok=True)

args.distributed = False 
print(args)

output_dir = Path(args.output_dir)
if args.resume:
  # the model will download the weights and model state from the https link provided 
  if args.resume.startswith('https'):
    checkpoint = torch.hub.load_state_dict_from_url(
        args.resume, map_location = 'cpu', check_hash = True
    ) 
  else:
    checkpoint = torch.load(args.resume, map_location='cpu')
  
  # this load the weights and model state into the model 
  model.load_state_dict(checkpoint['model'], strict = True)

the_image = PIL.Image.open('/content/000000286553.jpg')
scores, boxes = detect(the_image, model, transform)

plot_classes = ['person']

plot_results(the_image, scores, boxes, plot_classes)